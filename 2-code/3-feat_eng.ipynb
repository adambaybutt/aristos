{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6359323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a96b5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPanelFeatures(panel_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ''' Form all features at panel level.\n",
    "    \n",
    "    Args:\n",
    "        panel_df (pd.DataFrame): raw minute-level panel of BTC and ETH: usd per token prices, \n",
    "                                 token volume, and trade count.\n",
    "    \n",
    "    Returns:\n",
    "        panel_df (pd.DataFrame): panel data with features and without raw columns.\n",
    "    '''\n",
    "    # simple returns\n",
    "    for t in [1, 2, 3, 4, 5, 10, 15, 20, 30, 60, 120, 360, 365, 720, \n",
    "              1440, 4320, 8640, 20160, 40320, 86400]:\n",
    "        panel_df['covar_r_tm'+str(t)] = panel_df.groupby('asset')['price'].pct_change(periods=t)\n",
    "\n",
    "    # moments of 1 minute returns\n",
    "    for t in [5, 10, 20, 30, 60, 360, 720, 4320, 8640, 20160]:\n",
    "        panel_df['covar_r_1min_ma_tm'+str(t)]   = panel_df.groupby('asset')['covar_r_tm1'].transform(\n",
    "                                                        lambda x: x.rolling(t).mean())\n",
    "        panel_df['covar_r_1min_ema_tm'+str(t)]  = panel_df.groupby('asset')['covar_r_tm1'].transform(\n",
    "                                                        lambda x: x.ewm(span=t, adjust=False).mean())\n",
    "        panel_df['covar_r_1min_vol_tm'+str(t)]  = panel_df.groupby('asset')['covar_r_tm1'].transform(\n",
    "                                                        lambda x: x.rolling(t).std())\n",
    "        panel_df['covar_r_1min_skew_tm'+str(t)] = panel_df.groupby('asset')['covar_r_tm1'].transform(\n",
    "                                                        lambda x: x.rolling(t).skew())\n",
    "        panel_df['covar_r_1min_kurt_tm'+str(t)] = panel_df.groupby('asset')['covar_r_tm1'].transform(\n",
    "                                                        lambda x: x.rolling(t).kurt())\n",
    "\n",
    "    # moments of 5 minute returns\n",
    "    for t in [30, 60, 720, 4320, 8640, 20160]:\n",
    "        panel_df['covar_r_5min_ma_tm'+str(t)]   = panel_df.groupby('asset')['covar_r_tm5'].transform(\n",
    "                                                                    lambda x: x.rolling(t).mean())\n",
    "        panel_df['covar_r_5min_min_tm'+str(t)]  = panel_df.groupby('asset')['covar_r_tm5'].transform(\n",
    "                                                                    lambda x: x.rolling(t).min())\n",
    "        panel_df['covar_r_5min_max_tm'+str(t)]  = panel_df.groupby('asset')['covar_r_tm5'].transform(\n",
    "                                                                    lambda x: x.rolling(t).max())\n",
    "        panel_df['covar_r_5min_vol_tm'+str(t)]  = panel_df.groupby('asset')['covar_r_tm5'].transform(\n",
    "                                                                    lambda x: x.rolling(t).std())\n",
    "        panel_df['covar_r_5min_skew_tm'+str(t)] = panel_df.groupby('asset')['covar_r_tm5'].transform(\n",
    "                                                                    lambda x: x.rolling(t).skew())\n",
    "        panel_df['covar_r_5min_kurt_tm'+str(t)] = panel_df.groupby('asset')['covar_r_tm5'].transform(\n",
    "                                                                    lambda x: x.rolling(t).kurt())\n",
    "\n",
    "    # form price variables\n",
    "    panel_df = panel_df.rename(columns = {'price': 'covar_p_t'})\n",
    "    panel_df['covar_p_log_t'] = np.log(panel_df.covar_p_t)\n",
    "\n",
    "    # current volume\n",
    "    panel_df = panel_df.rename(columns = {'volume': 'covar_volume_t',\n",
    "                                          'trades': 'covar_trades_t'})\n",
    "\n",
    "    # form functions of volume\n",
    "    for col in ['covar_volume_t', 'covar_trades_t']:\n",
    "        for t in [5, 10, 20, 30, 60, 360, 720, 4320, 8640, 20160]:\n",
    "            panel_df['covar_'+col+'_ma_tm'+str(t)]  = panel_df.groupby('asset')[col].transform(\n",
    "                                                                    lambda x: x.rolling(t).mean())\n",
    "            panel_df['covar_'+col+'_sum_tm'+str(t)] = panel_df.groupby('asset')[col].transform(\n",
    "                                                                    lambda x: x.rolling(t).sum())                                                                        \n",
    "            panel_df['covar_'+col+'_min_tm'+str(t)] = panel_df.groupby('asset')[col].transform(\n",
    "                                                                    lambda x: x.rolling(t).min()) \n",
    "            panel_df['covar_'+col+'_max_tm'+str(t)] = panel_df.groupby('asset')[col].transform(\n",
    "                                                                    lambda x: x.rolling(t).max()) \n",
    "            panel_df['covar_'+col+'_vol_tm'+str(t)] = panel_df.groupby('asset')[col].transform(\n",
    "                                                                    lambda x: x.rolling(t).std()) \n",
    "    \n",
    "    # form returns from cum max and min prices\n",
    "    panel_df['covar_r_cummax_t'] = ((panel_df.covar_p_t - panel_df.covar_p_t.cummax()) \n",
    "                                    / panel_df.covar_p_t.cummax())\n",
    "    panel_df['covar_r_cummin_t'] = ((panel_df.covar_p_t - panel_df.covar_p_t.cummin()) \n",
    "                                    / panel_df.covar_p_t.cummin())\n",
    "\n",
    "    return panel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c693d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def renameColumnsWithAssetName(temp_df: pd.DataFrame, asset: str) -> pd.DataFrame:\n",
    "    ''' Helper function to rename columns with asset name at specific point in feature name.\n",
    "\n",
    "    Args:\n",
    "        asset (str): asset abbreviation to include in column names.\n",
    "    \n",
    "    Returns:\n",
    "        temp_df (pd.DataFrame): same data frame with new column names.\n",
    "    '''\n",
    "    # obtain list of features\n",
    "    cols = list(temp_df.columns.values)\n",
    "    cols.remove('date')\n",
    "\n",
    "    # initialize dictionary to use to rename\n",
    "    col_rename_dict = {}\n",
    "\n",
    "    # build dictionary to rename\n",
    "    for col in cols:\n",
    "        assert(col[:6] == 'covar_')\n",
    "        col_rename_dict[col] = 'covar_'+asset+'_'+col[6:]\n",
    "\n",
    "    # execute rename\n",
    "    temp_df = temp_df.rename(columns=col_rename_dict)\n",
    "\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baf4913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapseToTimeBars(panel_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ''' Collapse panel to time bars, ensuring no missing dates.\n",
    "    \n",
    "    Args: \n",
    "        panel_df (pd.DataFrame): panel data with features and without raw columns.\n",
    "\n",
    "    Returns:\n",
    "        df (pd.DataFrame): time bar level data with RHS features.\n",
    "    '''\n",
    "\n",
    "    # form seperate dataframes\n",
    "    btc_df = panel_df[panel_df.asset=='btc'].copy()\n",
    "    eth_df = panel_df[panel_df.asset=='eth'].copy()\n",
    "\n",
    "    # drop unnecessary column\n",
    "    btc_df = btc_df.drop('asset', axis=1)\n",
    "    eth_df = eth_df.drop('asset', axis=1)\n",
    "\n",
    "    # rename columns with asset name\n",
    "    btc_df = renameColumnsWithAssetName(btc_df, 'btc')\n",
    "    eth_df = renameColumnsWithAssetName(eth_df, 'eth')\n",
    "\n",
    "    # merge\n",
    "    df = btc_df.merge(eth_df, \n",
    "                      on=['date'],\n",
    "                      how='inner',\n",
    "                      validate='one_to_one')\n",
    "\n",
    "    # ensure no missing time bars\n",
    "    min_date = np.min(df.date.values)\n",
    "    max_date = np.max(df.date.values)\n",
    "    number_of_bars = 1+int(max_date - min_date)/1e9/60 # ns to seconds to minutes plus one minute\n",
    "    assert(df.shape[0] == number_of_bars)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d036873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLHSVariables(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ''' Create LHS target variables in binary and absolute return difference versions.\n",
    "        Decided to go with six hour frequency as about 90% of the windows have return difference\n",
    "        such that if forecasted accurately profit would be above fees.\n",
    "        Window is from every six hours (starting midnight) plus five minutes (to give time to \n",
    "        pull data and predict) to the subsequent six hours plus 10 minutes (to repeat the process \n",
    "        and give time to place/update trades).\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): time bar level data with only RHS features.\n",
    "    \n",
    "    Returns:\n",
    "        df (pd.DataFrame): time bar level data with LHS and RHS features.\n",
    "    '''\n",
    "    # form temporary columns of btc and eth returns over target window\n",
    "    df['temp_btc_r_tp5_tp370'] = df.covar_btc_r_tm365.shift(-370)\n",
    "    df['temp_eth_r_tp5_tp370'] = df.covar_eth_r_tm365.shift(-370)\n",
    "\n",
    "    # form binary LHS outcome y where 1 if BTC outperforms and 0 otherwise\n",
    "    df.loc[df.temp_btc_r_tp5_tp370 >= df.temp_eth_r_tp5_tp370, 'y'] = 1\n",
    "    df.loc[df.temp_btc_r_tp5_tp370 < df.temp_eth_r_tp5_tp370, 'y'] = 0\n",
    "\n",
    "    # form real valued LHS outcome for return difference\n",
    "    df['y_btc_eth_diff_r_tp5_tp370'] = df.temp_btc_r_tp5_tp370 - df.temp_eth_r_tp5_tp370\n",
    "\n",
    "    # drop temporary columns\n",
    "    df = df.drop(['temp_btc_r_tp5_tp370', 'temp_eth_r_tp5_tp370'], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "341eca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRSIFeatures(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ''' Form relative strength index features at one hour frequency over various windows.\n",
    "\n",
    "    Args: \n",
    "        df (pd.DataFrame): time bar level data with necessary RHS features.\n",
    "    \n",
    "    Returns:\n",
    "        df (pd.DataFrame): same time bar level data frame with RSI features added.    \n",
    "\n",
    "    FUTURE TODO:\n",
    "        -convert code to work at panel level instead of time bar level\n",
    "        -pass in freq to work at, noting units\n",
    "        -pass in windows to create, noting units\n",
    "        -make generic function in my relevant class\n",
    "    '''\n",
    "\n",
    "    for asset in ['btc', 'eth']:\n",
    "        for window in [360, 720, 4320, 8640, 20160]:\n",
    "            one_hr_p_delta_col = 'covar_'+asset+'_p_delta_tm12'\n",
    "            df[one_hr_p_delta_col] = df['covar_'+asset+'_p_t'].diff(periods=12)\n",
    "            df['temp_'+asset+'neg_p_delta_1hr'] = df[one_hr_p_delta_col].clip(upper=0)\n",
    "            df['temp_'+asset+'pos_p_delta_1hr'] = -1*df[one_hr_p_delta_col].clip(lower=0)\n",
    "            df['temp_'+asset+'_avg_neg_p_delta_1hr_tm'+str(window)] = df['temp_'+asset+'neg_p_delta_1hr'].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "            df['temp_'+asset+'_avg_pos_p_delta_1hr_tm'+str(window)] = df['temp_'+asset+'pos_p_delta_1hr'].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "            df['covar_'+asset+'_rsi_tm'+str(window)] = (100 - 100/(1 + \n",
    "                                                                df['temp_'+asset+'_avg_pos_p_delta_1hr_tm'+str(window)]/\n",
    "                                                                df['temp_'+asset+'_avg_neg_p_delta_1hr_tm'+str(window)]))\n",
    "            df = df.drop(['temp_'+asset+'neg_p_delta_1hr', \n",
    "                        'temp_'+asset+'pos_p_delta_1hr',\n",
    "                        'temp_'+asset+'_avg_neg_p_delta_1hr_tm'+str(window),\n",
    "                        'temp_'+asset+'_avg_pos_p_delta_1hr_tm'+str(window)], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "029b6dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFeaturesLHSAndCollapseToTimeBars(panel_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ''' Transform raw panel to time bars with clean LHS and RHS features.\n",
    "    \n",
    "    Args:\n",
    "        panel_df (pd.DataFrame): raw minute-level panel of BTC and ETH:\n",
    "                                 usd per token prices, token volume, and trade count.\n",
    "    \n",
    "    Returns:\n",
    "        df (pd.DataFrame): time bars of LHS and RHS features.\n",
    "    '''\n",
    "    # form features\n",
    "    panel_df = createPanelFeatures(panel_df)\n",
    "\n",
    "    # form LHS and collapse\n",
    "    df = collapseToTimeBars(panel_df)\n",
    "    df = createLHSVariables(df)\n",
    "    \n",
    "    # form rsi features (needs to be time bar data for the code i have)\n",
    "    df = createRSIFeatures(df)\n",
    "\n",
    "    # resample to target frequency of every six hours\n",
    "    df = df[df.date.dt.hour.isin([0,6,12,18]) & (df.date.dt.minute==0)].reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77cbd314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalClean(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ''' Final checks and clean of the time bar data.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): time bar level data with LHS and RHS features.\n",
    "\n",
    "    Returns:\n",
    "        df (pd.DataFrame): clean time bar level data with sorted columns and rows.    \n",
    "    '''\n",
    "    # interpolate missing values in skew, kurt, and rsi columns with trailing four day mean\n",
    "    periods = 16 # four days\n",
    "    cols = list(df.columns.values)\n",
    "    interpol_cols = [col for col in cols if ('rsi' in col) | ('kurt' in col) | ('skew' in col)]\n",
    "    for col in interpol_cols:\n",
    "        df['rolling_average'] = df[col].rolling(periods, min_periods=1).mean()\n",
    "        df[col] = df[col].fillna(df['rolling_average'])\n",
    "        df = df.drop('rolling_average', axis=1)\n",
    "\n",
    "    # drop rows pre 2016 and post June 2022\n",
    "    df = df[df.date.dt.year >= 2016]\n",
    "    df = df[~((df.date.dt.year == 2022) & (df.date.dt.month == 6))]\n",
    "\n",
    "    # order columns\n",
    "    cols = list(df.columns.values)\n",
    "    cols.remove('date')\n",
    "    cols.remove('y')\n",
    "    cols.remove('y_btc_eth_diff_r_tp5_tp370')\n",
    "    sorted_cols = sorted(cols)\n",
    "    df = df[['date', 'y', 'y_btc_eth_diff_r_tp5_tp370']+sorted_cols]\n",
    "\n",
    "    # ensure rows are sorted\n",
    "    df = df.sort_values(by='date', ignore_index=True)\n",
    "\n",
    "    # ensure there are the correct number of rows\n",
    "    min_date = np.min(df.date.values)\n",
    "    max_date = np.max(df.date.values)\n",
    "    number_of_bars = 1+int(max_date - min_date)/1e9/60/60/24*4 # ns to sec to quarter days plus one bar\n",
    "    assert(df.shape[0] == number_of_bars)\n",
    "\n",
    "    # drop columns missing any data\n",
    "    num_cols_pre = df.shape[1]\n",
    "    df = df.dropna(axis=1)\n",
    "    print('dropped '+str(int(df.shape[1]-num_cols_pre))+' columns that were still missing data.')\n",
    "\n",
    "    # ensure no missing data\n",
    "    assert(0==df.isnull().sum().sum()),('there is missing data to be fixed in the time bar data.')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c3df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcCorrelationStatistics(df: pd.DataFrame, fp: str):\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37797667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO do the corr, *spearman rank*, MI, consistency, indep by year and overall as before\n",
    "# choose covars and be generous here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e5edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO scatterplot of each RHS with LHS to just get a feel of stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6fbca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "# not sure what i mean by this but\n",
    "# confirm signal with low dim linear regression\n",
    "# maybe lasso like the final set to choose some so i work with lower dim problem?\n",
    "# then start with just linear reg to ensure it works on this low dim set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd42062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO final clean\n",
    "# save the final panel in clean data folder as the full panel, ensure no missing, all vars have proper range, set col order, set col name, reset index, save as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97ac5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # set args\n",
    "    in_fp       = '../1-data/clean/panel_btceth_1min.pkl'\n",
    "    fe_stats_fp = '../3-output/feat_eng_stats.csv'\n",
    "\n",
    "    # read in data\n",
    "    panel_df = pd.read_pickle(in_fp)\n",
    "\n",
    "    # engineer features\n",
    "    df = createFeaturesLHSAndCollapseToTimeBars(panel_df)\n",
    "    \n",
    "    # ensure time bar data is clean\n",
    "    df = finalClean(df)\n",
    "\n",
    "    # calculate correlation statistics\n",
    "    #calcCorrelationStatistics(df, fe_stats_fp)\n",
    "\n",
    "    # step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14903da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ONCE DONE WITH THIS; TURN INTO PYTHON SCRIPT\n",
    "# TODO MOVE ANY FUNCTIONS THAT I MAY USE ELSEWHERE TO COMMON FOLDER SHARED ACROSS PROJECTS THAT I JUST IMPORT WHEN NEEDED"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e428bc405edc59f3352e9792cab27c5e28560f7efb4b47308a6c6ea38cd15df2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
