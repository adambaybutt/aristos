{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6359323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "from datetime import date\n",
    "from requests import Request, Session\n",
    "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
    "import json\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bbd9e038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': {'timestamp': '2022-08-29T23:23:23.097Z', 'error_code': 0, 'error_message': None, 'elapsed': 4, 'credit_count': 0, 'notice': \"You have used 300% of your plan's daily credit limit.\"}, 'data': {'plan': {'credit_limit_daily': 16666, 'credit_limit_daily_reset': 'In 16 hours, 48 minutes', 'credit_limit_daily_reset_timestamp': '2022-08-30T16:12:20.000Z', 'credit_limit_monthly': 500000, 'credit_limit_monthly_reset': 'In 28 days, 16 hours, 48 minutes', 'credit_limit_monthly_reset_timestamp': '2022-09-27T16:12:20.000Z', 'rate_limit_minute': 60}, 'usage': {'current_minute': {'requests_made': 1, 'requests_left': 59}, 'current_day': {'credits_used': 50024, 'credits_left': -33358}, 'current_month': {'credits_used': 50024, 'credits_left': 449976}}}}\n"
     ]
    }
   ],
   "source": [
    "# API SET UP\n",
    "\n",
    "# coinmarketcap key\n",
    "fp = '../0-admin/coinmarketcap_standard.txt'\n",
    "\n",
    "with open(fp) as f:\n",
    "    API_KEY = f.readlines()\n",
    "    API_KEY = API_KEY[0].strip()\n",
    "    \n",
    "# Set up API\n",
    "base_url = \"https://pro-api.coinmarketcap.com\"\n",
    "headers = {'Accepts': 'application/json',\n",
    "           'X-CMC_PRO_API_KEY': API_KEY}\n",
    "\n",
    "# Test it is working\n",
    "endpoint = '/v1/key/info'\n",
    "final_url = base_url + endpoint\n",
    "session = Session()\n",
    "session.headers.update(headers)\n",
    "r = session.get(final_url)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "952a3b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-31\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "json has error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [93]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m \u001b[38;5;66;03m# skip if the data is not in the range of interest\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson has error\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mConnectionError\u001b[39;00m, Timeout, TooManyRedirects) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(e)\n",
      "\u001b[0;31mAssertionError\u001b[0m: json has error"
     ]
    }
   ],
   "source": [
    "# OBTAIN PRICE VOLUME AND MCAP DATA\n",
    "\n",
    "# Note: this call takes a few minutes.\n",
    "# Obtain price, volume, and mcap data\n",
    "token_dfs = []\n",
    "btc_eth_cmc_ids = [1, 1027]\n",
    "\n",
    "# Specify the dates to obtain\n",
    "first_date = '2017-11-30'\n",
    "last_date  = '2022-09-05'\n",
    "dates      = pd.date_range(first_date,\n",
    "                           last_date,\n",
    "                           freq='M').strftime(\"%Y-%m-%d\").tolist()\n",
    "\n",
    "# Repeat for all 1 month intervals for BTC and ETH\n",
    "for token_id in btc_eth_cmc_ids:\n",
    "    for i in range(0,len(dates)-1):\n",
    "        # specify dates\n",
    "        start_date = dates[i]\n",
    "        end_date   = dates[i+1]\n",
    "        print(end_date)\n",
    "\n",
    "        # Set up the call\n",
    "        endpoint = '/v1/cryptocurrency/quotes/historical'\n",
    "        final_url = base_url+endpoint\n",
    "        token_id = str(token_id)\n",
    "        parameters = {'id': token_id,\n",
    "                      'time_start': start_date,\n",
    "                      'time_end': end_date,\n",
    "                      'count': 10000,\n",
    "                      'interval': '5m',\n",
    "                      'convert': 'USD'}\n",
    "\n",
    "        # Make the call\n",
    "        try:\n",
    "            response = session.get(final_url, params=parameters)\n",
    "            r_json = json.loads(response.text)\n",
    "            if (r_json['status']['error_message'] == None):\n",
    "                data = r_json['data']\n",
    "            elif (r_json['status']['error_message'][:29] == 'Search query is out of range.'):\n",
    "                continue # skip if the data is not in the range of interest\n",
    "            else:\n",
    "                assert(1==0),'json has error'\n",
    "\n",
    "        except (ConnectionError, Timeout, TooManyRedirects) as e:\n",
    "            print(e)\n",
    "            print('\\n')\n",
    "\n",
    "        # Add the cleaned up data as a data frame\n",
    "        token_quote_dict_list = []\n",
    "        for quote in data['quotes']:\n",
    "            new_dict = {}\n",
    "            new_dict['date']           = quote['quote']['USD']['timestamp']\n",
    "            new_dict['usd_per_token']  = quote['quote']['USD']['price']\n",
    "            new_dict['usd_volume_24h'] = quote['quote']['USD']['volume_24h']\n",
    "            new_dict['usd_mcap']       = quote['quote']['USD']['market_cap']\n",
    "            token_quote_dict_list.append(new_dict)\n",
    "\n",
    "        token_df = pd.DataFrame(token_quote_dict_list)\n",
    "        token_df['cmc_id'] = data['id']\n",
    "        token_dfs.append(token_df)\n",
    "\n",
    "        # space out calls and track\n",
    "        time.sleep(1)\n",
    "\n",
    "# clean up the data\n",
    "df = pd.concat(token_dfs)\n",
    "df = df[['date', 'cmc_id', 'usd_per_token', 'usd_volume_24h', 'usd_mcap']]\n",
    "df['date'] = pd.to_datetime(df.date).dt.tz_localize(None)\n",
    "df['date'] = df.date.dt.ceil('5min')\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates(subset=['date', 'cmc_id'])\n",
    "dates_df = pd.concat((pd.DataFrame(data={'date': pd.date_range(first_date, last_date, freq='5min'),\n",
    "                                        'cmc_id': 1}),\n",
    "                      pd.DataFrame(data={'date': pd.date_range(first_date, last_date, freq='5min'),\n",
    "                                        'cmc_id': 1027})))\n",
    "df = df.merge(dates_df,\n",
    "              on=['date', 'cmc_id'],\n",
    "              how='outer',\n",
    "              validate='one_to_one')\n",
    "df = df.sort_values(by=['cmc_id', 'date'], ignore_index=True)\n",
    "df = df.interpolate(method='ffill', limit_area='inside')\n",
    "df = df.dropna()\n",
    "assert(0==df.isnull().sum().sum())\n",
    "df = df.sort_values(by=['date', 'cmc_id'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012180f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~((df.date.dt.year==2017)&(df.date.dt.month==11))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040be723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBTAIN GLOBAL COINMARKETCAP DATA\n",
    "# NOTE: this takes about 5 minutes\n",
    "macro_dfs = []\n",
    "\n",
    "# Repeat for all 1 month intervals for BTC and ETH\n",
    "for i in range(0,len(dates)-1):\n",
    "    # specify dates\n",
    "    start_date = dates[i]\n",
    "    end_date   = dates[i+1]\n",
    "\n",
    "    # Set up the call\n",
    "    endpoint = '/v1/global-metrics/quotes/historical'\n",
    "    final_url = base_url+endpoint\n",
    "    parameters = {'time_start': start_date,\n",
    "                  'time_end': end_date,\n",
    "                  'count': 2,\n",
    "                  'interval': '5m',\n",
    "                  'convert': 'USD',\n",
    "                  'aux': 'btc_dominance,total_volume_24h,altcoin_market_cap'}\n",
    "\n",
    "    response = session.get(final_url, params=parameters)\n",
    "    r_json = json.loads(response.text)\n",
    "\n",
    "    # Initialize dictionary for the data\n",
    "    cmc_macro_dict = {'date': [],\n",
    "                      'total_volume_24h': [],\n",
    "                      'altcoin_market_cap': [],\n",
    "                      'btc_dominance': []}\n",
    "\n",
    "    # Convert JSON into dictionary\n",
    "    for token in r_json['data']['quotes']:\n",
    "        cmc_macro_dict['date'].append(token['timestamp'])\n",
    "        cmc_macro_dict['total_volume_24h'].append(token['quote']['USD']['total_volume_24h'])\n",
    "        cmc_macro_dict['altcoin_market_cap'].append(token['quote']['USD']['altcoin_market_cap'])\n",
    "        cmc_macro_dict['btc_dominance'].append(token['btc_dominance'])\n",
    "\n",
    "    # Cut out duplicated dates in macro data\n",
    "    macro_df = pd.DataFrame(cmc_macro_dict)\n",
    "    macro_df = macro_df[macro_df.index.isin(macro_df['date'].drop_duplicates().index)]\n",
    "\n",
    "    # Append\n",
    "    macro_dfs.append(macro_df)\n",
    "\n",
    "    # space out calls and track\n",
    "    time.sleep(1)\n",
    "\n",
    "# Clean up the macro dataframe to have all study period dates and interpolate missing dates\n",
    "macro_df = pd.concat(macro_dfs)\n",
    "macro_df['date'] = pd.to_datetime(macro_df.date).dt.tz_localize(None)\n",
    "macro_df['date'] = macro_df.date.dt.ceil('5min')\n",
    "macro_df = macro_df.drop_duplicates(subset='date')\n",
    "df = df.dropna()\n",
    "dates_df = pd.DataFrame(data={'date': pd.date_range(first_date, last_date, freq='5min')})\n",
    "macro_df = macro_df.merge(dates_df,\n",
    "                          on='date',\n",
    "                          how='outer',\n",
    "                          validate='one_to_one')\n",
    "\n",
    "macro_df = macro_df.sort_values(by='date', ignore_index=True)\n",
    "macro_df = macro_df.interpolate(method='ffill', limit_area='inside')\n",
    "macro_df = macro_df.dropna()\n",
    "assert(0==macro_df.isnull().sum().sum())\n",
    "macro_df = macro_df.sort_values(by='date', ignore_index=True)\n",
    "macro_df['date'] += pd.Timedelta(minutes=5) # DATA HAS 5 MIN OF LATENCY SO WE HAVE TO LAG IT BY 5 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a8a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_df = macro_df[~((macro_df.date.dt.year==2017)&(macro_df.date.dt.month==11))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5a7de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO FIX BELOW CODE!\n",
    "\n",
    "# READ IN THE OLD DATA\n",
    "old_df        = pd.read_csv('../3-data/raw/cmc_price_vol_mcap_btceth_5min-20171201_20220824.csv')\n",
    "old_macro_df  = pd.read_csv('../3-data/raw/cmc_macro_timeseries_btceth_5min-20171201_20220824.csv')\n",
    "\n",
    "# COMBINE DATA\n",
    "\n",
    "# drop dates in the existing data from the new data pulled\n",
    "last_date_old_main_data  = np.max(old_df.date.values)\n",
    "df                       = df[df.date>last_date_old_main_data]\n",
    "last_date_old_macro_data = np.max(old_macro_df.date.values)\n",
    "macro_df                 = macro_df[macro_df.date>last_date_old_macro_data]\n",
    "\n",
    "# put data together\n",
    "df = pd.concat((old_df, df)).reset_index(drop=True)\n",
    "macro_df = pd.concat((old_macro_df, macro_df)).reset_index(drop=True)\n",
    "\n",
    "# sort\n",
    "df            = df.sort_values(by=['date', 'cmc_id'])\n",
    "macro_df      = macro_df.sort_values(by=['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "1db1fb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>total_volume_24h</th>\n",
       "      <th>altcoin_market_cap</th>\n",
       "      <th>btc_dominance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-30T00:07:00.000Z</td>\n",
       "      <td>2.427597e+10</td>\n",
       "      <td>1.296200e+11</td>\n",
       "      <td>56.113804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-30T00:12:00.000Z</td>\n",
       "      <td>2.442784e+10</td>\n",
       "      <td>1.305865e+11</td>\n",
       "      <td>56.026665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-30T00:17:00.000Z</td>\n",
       "      <td>2.470249e+10</td>\n",
       "      <td>1.319481e+11</td>\n",
       "      <td>56.087906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-30T00:22:00.000Z</td>\n",
       "      <td>2.500412e+10</td>\n",
       "      <td>1.338523e+11</td>\n",
       "      <td>55.931969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-30T00:27:00.000Z</td>\n",
       "      <td>2.511601e+10</td>\n",
       "      <td>1.341620e+11</td>\n",
       "      <td>55.986496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7478</th>\n",
       "      <td>2022-08-25T23:20:00.000Z</td>\n",
       "      <td>6.434394e+10</td>\n",
       "      <td>6.288437e+11</td>\n",
       "      <td>39.616971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7479</th>\n",
       "      <td>2022-08-25T23:25:00.000Z</td>\n",
       "      <td>6.439341e+10</td>\n",
       "      <td>6.293038e+11</td>\n",
       "      <td>39.611672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7480</th>\n",
       "      <td>2022-08-25T23:30:00.000Z</td>\n",
       "      <td>6.431970e+10</td>\n",
       "      <td>6.298418e+11</td>\n",
       "      <td>39.618041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7481</th>\n",
       "      <td>2022-08-25T23:35:00.000Z</td>\n",
       "      <td>6.429181e+10</td>\n",
       "      <td>6.298992e+11</td>\n",
       "      <td>39.619576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7482</th>\n",
       "      <td>2022-08-25T23:40:00.000Z</td>\n",
       "      <td>6.414061e+10</td>\n",
       "      <td>6.297288e+11</td>\n",
       "      <td>39.617976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496192 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date  total_volume_24h  altcoin_market_cap  \\\n",
       "0     2017-11-30T00:07:00.000Z      2.427597e+10        1.296200e+11   \n",
       "1     2017-11-30T00:12:00.000Z      2.442784e+10        1.305865e+11   \n",
       "2     2017-11-30T00:17:00.000Z      2.470249e+10        1.319481e+11   \n",
       "3     2017-11-30T00:22:00.000Z      2.500412e+10        1.338523e+11   \n",
       "4     2017-11-30T00:27:00.000Z      2.511601e+10        1.341620e+11   \n",
       "...                        ...               ...                 ...   \n",
       "7478  2022-08-25T23:20:00.000Z      6.434394e+10        6.288437e+11   \n",
       "7479  2022-08-25T23:25:00.000Z      6.439341e+10        6.293038e+11   \n",
       "7480  2022-08-25T23:30:00.000Z      6.431970e+10        6.298418e+11   \n",
       "7481  2022-08-25T23:35:00.000Z      6.429181e+10        6.298992e+11   \n",
       "7482  2022-08-25T23:40:00.000Z      6.414061e+10        6.297288e+11   \n",
       "\n",
       "      btc_dominance  \n",
       "0         56.113804  \n",
       "1         56.026665  \n",
       "2         56.087906  \n",
       "3         55.931969  \n",
       "4         55.986496  \n",
       "...             ...  \n",
       "7478      39.616971  \n",
       "7479      39.611672  \n",
       "7480      39.618041  \n",
       "7481      39.619576  \n",
       "7482      39.617976  \n",
       "\n",
       "[496192 rows x 4 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## SAVE DATA\n",
    "\n",
    "df.to_csv('../3-data/raw/cmc_price_vol_mcap_btceth_5min.csv', index=False)\n",
    "macro_df.to_csv('../3-data/raw/cmc_macro_timeseries_btceth_5min.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a4ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP TODO\n",
    "\n",
    "# DROP NOV 2017 DATA\n",
    "# DROP AUGUST 29 DATA FROM TODAY\n",
    "\n",
    "# GO DELETE THAT OLD FILE FOR BOTH SO I DONT CARRY AROUND THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec93bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE DATA TO NEW DATES IF IT IS A NEW MONTH\n",
    "\n",
    "df.to_csv('../3-data/raw/cmc_price_vol_mcap_btceth_5min-20171201_20220828.csv', index=False)\n",
    "macro_df.to_csv('../3-data/raw/cmc_macro_timeseries_btceth_5min-20171201_20220828.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
